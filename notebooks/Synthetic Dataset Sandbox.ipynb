{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f4127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import nerf_model\n",
    "import dataloader\n",
    "\n",
    "import plotly\n",
    "import torch \n",
    "import cv2\n",
    "from PIL import Image\n",
    "import itertools \n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20cc186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload \n",
    "dataloader = reload(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d93336",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataloader.SyntheticDataset('../data/toy_data/', 'train', 4096)\n",
    "dl = dataloader.getSyntheticDataloader('../data/toy_data/', 'train', 4096)\n",
    "batch = next(iter(dl))\n",
    "print(batch.keys())\n",
    "# images = batch['image']\n",
    "# poses = batch['cam_to_world']\n",
    "# N, C, H, W = images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0162db",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['origin'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5564ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(coords, rgb): \n",
    "    a, b = coords.shape\n",
    "    if b == 4:\n",
    "        coords = coords.T\n",
    "    d, N = coords.shape\n",
    "    if type(rgb) != str:\n",
    "        rgb = rgb.T\n",
    "    plot_fig = go.Scatter3d(x=coords[0], y=coords[1], z=coords[2], \n",
    "    mode='markers', marker=dict(\n",
    "       size=2,\n",
    "       color=rgb\n",
    "    ))\n",
    "    return plot_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb303bb",
   "metadata": {},
   "source": [
    "## Figuring out how to convert images to rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a743eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ndc_rays(o_rays, d_rays, focal, width, height, near=1.0): \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        d_rays: [N x 4] representing ray direction \n",
    "        o_rays: [N x 4] representing ray origin \n",
    "        angle: camera_angle_x\n",
    "        width: the maximum width \n",
    "        height: the maximum height\n",
    "        near: the near depth bound (i.e. 1)\n",
    "    \"\"\"\n",
    "    t_near  = - (near + o_rays[:,:,2] ) / d_rays[:,:,2] \n",
    "    o_rays = o_rays + t_near[...,None] * d_rays\n",
    "    ox, oy, oz = o_rays[:,:,0], o_rays[:,:,1], o_rays[:,:,2] \n",
    "    dx, dy, dz = d_rays[:,:,0], d_rays[:,:,1], d_rays[:,:,2] \n",
    "    \n",
    "    ox_new =  -1.0 * focal / (width / 2) * (ox / oz)\n",
    "    oy_new =  -1.0 * focal / (height / 2) * (oy / oz)\n",
    "    oz_new = 1.0 + (2 * near) / oz\n",
    "    \n",
    "    dx_new =  -1.0 * focal / (width / 2) * ((dx / dz) - (ox / oz))\n",
    "    dy_new =  -1.0 * focal / (height / 2) * ((dy / dz) - (oy / oz))\n",
    "    dz_new = (- 2 * near) / oz\n",
    "    \n",
    "    o_rays_new = torch.stack([ox_new, oy_new, oz_new], axis=-1)\n",
    "    d_rays_new = torch.stack([dx_new, dy_new, dz_new], axis=-1)\n",
    "    \n",
    "    return o_rays_new, d_rays_new\n",
    "\n",
    "def ndc_rays(H, W, focal, near, rays_o, rays_d):\n",
    "    \"\"\"Normalized device coordinate rays.\n",
    "    Space such that the canvas is a cube with sides [-1, 1] in each axis.\n",
    "    Args:\n",
    "      H: int. Height in pixels.\n",
    "      W: int. Width in pixels.\n",
    "      focal: float. Focal length of pinhole camera.\n",
    "      near: float or array of shape[batch_size]. Near depth bound for the scene.\n",
    "      rays_o: array of shape [batch_size, 3]. Camera origin.\n",
    "      rays_d: array of shape [batch_size, 3]. Ray direction.\n",
    "    Returns:\n",
    "      rays_o: array of shape [batch_size, 3]. Camera origin in NDC.\n",
    "      rays_d: array of shape [batch_size, 3]. Ray direction in NDC.\n",
    "    \"\"\"\n",
    "    # Shift ray origins to near plane\n",
    "    t = -(near + rays_o[..., 2]) / rays_d[..., 2]\n",
    "    rays_o = rays_o + t[..., None] * rays_d\n",
    "\n",
    "    # Projection\n",
    "    o0 = -1./(W/(2.*focal)) * rays_o[..., 0] / rays_o[..., 2]\n",
    "    o1 = -1./(H/(2.*focal)) * rays_o[..., 1] / rays_o[..., 2]\n",
    "    o2 = 1. + 2. * near / rays_o[..., 2]\n",
    "\n",
    "    d0 = -1./(W/(2.*focal)) * \\\n",
    "        (rays_d[..., 0]/rays_d[..., 2] - rays_o[..., 0]/rays_o[..., 2])\n",
    "    d1 = -1./(H/(2.*focal)) * \\\n",
    "        (rays_d[..., 1]/rays_d[..., 2] - rays_o[..., 1]/rays_o[..., 2])\n",
    "    d2 = -2. * near / rays_o[..., 2]\n",
    "\n",
    "    rays_o = torch.stack([o0, o1, o2], -1)\n",
    "    rays_d = torch.stack([d0, d1, d2], -1)\n",
    "\n",
    "    return rays_o, rays_d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e60a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "rays_o = torch.rand((1,10,3))\n",
    "rays_d = torch.rand((1,10,3))\n",
    "ndc_o_rays, ndc_d_rays = convert_to_ndc_rays(rays_o, rays_d, 0.6, 4, 4)\n",
    "\n",
    "bmild_o_rays, bmild_d_rays = ndc_rays(4, 4, 0.6, 1, rays_o.squeeze(0), rays_d.squeeze(0))\n",
    "np.testing.assert_allclose(ndc_o_rays.squeeze(0).numpy(), bmild_o_rays.numpy()) #, rtol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c143a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rays_o.shape)\n",
    "ndc_o_rays, ndc_d_rays = convert_to_ndc_rays(rays_o, rays_d, 0.6, 4, 4)\n",
    "\n",
    "print(ndc_o_rays.shape)\n",
    "\n",
    "bmild_o_rays, bmild_d_rays = ndc_rays(4, 4, 0.6, 1, rays_o, rays_d)\n",
    "\n",
    "np.testing.assert_allclose(ndc_o_rays.numpy(), bmild_o_rays.numpy(), rtol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_get_rays(H, W, focal, c2w):\n",
    "    \"\"\"Get ray origins, directions from a pinhole camera.\"\"\"\n",
    "    i, j = np.meshgrid(np.arange(W, dtype=np.float32),\n",
    "                       np.arange(H, dtype=np.float32), indexing='xy')\n",
    "    dirs = np.stack([(i-W*.5)/focal, -(j-H*.5)/focal, -np.ones_like(i)], -1)\n",
    "    rays_d = np.sum(dirs[..., np.newaxis, :] * c2w[:3, :3], -1)\n",
    "    rays_o = np.broadcast_to(c2w[:3, -1], np.shape(rays_d))\n",
    "    return rays_o, rays_d\n",
    "\n",
    "np_rays_o, np_rays_d = np_get_rays(4, 4, 0.6, pose.numpy())\n",
    "\n",
    "def get_rays(H, W, focal, c2w):\n",
    "    \"\"\"Get ray origins, directions from a pinhole camera.\"\"\"\n",
    "    i, j = torch.meshgrid(torch.arange(W, dtype=torch.float32),\n",
    "                       torch.arange(H, dtype=torch.float32), indexing='xy')\n",
    "    dirs = torch.stack([(i-W*.5)/focal, -(j-H*.5)/focal, -torch.ones_like(i)], -1)\n",
    "    rays_d = torch.sum(dirs[..., None, :] * c2w[:3, :3], -1)\n",
    "    rays_o = torch.broadcast_to(c2w[:3, -1], rays_d.shape)\n",
    "    return rays_o, rays_d\n",
    "\n",
    "rays_o, rays_d = get_rays(4, 4, 0.6, pose)\n",
    "\n",
    "np.testing.assert_allclose(rays_o.numpy(), np_rays_o)\n",
    "np.testing.assert_allclose(rays_d.numpy(), np_rays_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a025241",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = ds[0]['cam_to_world']\n",
    "origin = torch.Tensor([[0,0,0,1]]).T\n",
    "print(pose @ origin)\n",
    "print(pose[:3, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999aae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = dict(\n",
    "    up=dict(x=0, y=1, z=0),\n",
    "#     center=dict(x=0, y=0, z=0),\n",
    "#     eye=dict(x=1.25, y=1.25, z=1.25)\n",
    ")\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.update_layout(scene_camera=camera)\n",
    "for i, batch in enumerate(ds):\n",
    "    world_coords = batch['world_coords'] # [4096 x 4]\n",
    "    pixel_coords = batch['pixel_coords'] # [4096 x 4]\n",
    "    pixels = pixel_coords[:,:2].long() # [4096 x 2]\n",
    "    image = batch['image'] # [4 x 800 x800]\n",
    "    rgba = image[:, pixels[:,0], pixels[:,1]] # [4 x 4096]\n",
    "    idxs = rgba[3,:] >= 1e-5\n",
    "    rgb = rgba[:3, idxs]\n",
    "    world_coords = world_coords[idxs, :]\n",
    "    plot = visualize(world_coords, rgb)\n",
    "    cam = visualize(batch['cam_in_world'], 'blue')\n",
    "    \n",
    "    fig.add_trace(plot)\n",
    "    fig.add_trace(cam)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82580a9c",
   "metadata": {},
   "source": [
    "## Batch Training Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb442b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_coords = torch_generate_ih_coordinates(H, W, cam_angle)\n",
    "pixel_coords = pixel_coords.reshape((-1, 4)).T.unsqueeze(0)\n",
    "world_coords = torch.bmm(poses, pixel_coords).swapaxes(1,2)\n",
    "world_coords = world_coords.reshape((4, -1))[:3,:] # [::10]\n",
    "world_coords = world_coords[:,::10]\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "origin_fig = go.Scatter3d(x=world_coords[0], y=world_coords[1], z=world_coords[2], \n",
    "   mode='markers', marker=dict(\n",
    "       size=2,\n",
    "       color='purple'\n",
    "  ))\n",
    "fig.add_trace(origin_fig)\n",
    "fig.show()    \n",
    "\n",
    "# fig.write_html(\"./batch.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5088c0",
   "metadata": {},
   "source": [
    "## Plot all Datapoints\n",
    "can't really tell if its correct or not but it looks fairly close enough? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d87cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_angle = cam_angles[0]\n",
    "cam_coords = generate_ih_coordinates(H, W, cam_angle).reshape((-1, 4))\n",
    "camera = np.array([0,0,0,1]).reshape((4,1))\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "origin_fig = go.Scatter3d(x=[0], y=[0], z=[0], \n",
    "   mode='markers', marker=dict(\n",
    "       size=2,\n",
    "       color='purple'\n",
    "  ))\n",
    "fig.add_trace(origin_fig)\n",
    "\n",
    "for i in range(N):\n",
    "    image = images[i]; pose = poses[i]\n",
    "    image = image.numpy().reshape((4,-1))\n",
    "    opacity = image[3,:] > 1e-5; rgb = image[:3,opacity].T\n",
    "    hit_coords = cam_coords[opacity,:]\n",
    "    decimate = 20\n",
    "    rgb = rgb[::decimate]\n",
    "    hit_coords = hit_coords[::decimate].T\n",
    "    w_coords = (pose @ hit_coords)\n",
    "    img_fig = go.Scatter3d(x=w_coords[0], y=w_coords[2], z=w_coords[1],\n",
    "               mode='markers', marker=dict(\n",
    "                   size=1,\n",
    "                   color=rgb\n",
    "               ))\n",
    "    cam_pose = pose @ camera\n",
    "    cam_fig = go.Scatter3d(x=cam_pose[0], y=cam_pose[2], z=cam_pose[1],\n",
    "               mode='markers', marker=dict(\n",
    "                   size=5,\n",
    "                   color='red'\n",
    "               ))\n",
    "    fig.add_trace(img_fig)\n",
    "    fig.add_trace(cam_fig)\n",
    "    \n",
    "fig.show()    \n",
    "\n",
    "fig.write_html(\"./project_all.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b341aa5",
   "metadata": {},
   "source": [
    "## Plotting in Camera Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b603a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataloader.SyntheticDataset('../data/toy_data/', 'train')\n",
    "frame = ds[0]\n",
    "\n",
    "print(frame.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d155cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = np.array([0,0,0,1]).reshape((4,1))\n",
    "cam_points = [camera]\n",
    "for frame in ds:\n",
    "    c2w = frame['transform_matrix']\n",
    "    camera = np.array([0,0,0,1]).reshape((4,1))\n",
    "    point = c2w @ camera\n",
    "    cam_points.append(point)\n",
    "cam_points = np.stack(cam_points).reshape((-1,4))\n",
    "print(cam_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x, y, z, _ = cam_points.T\n",
    "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z,\n",
    "                                   mode='markers', marker=dict(\n",
    "                                       size=5,\n",
    "                                       color=['red'],\n",
    "                                   ))])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95fc63d",
   "metadata": {},
   "source": [
    "## Plotting in World Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d98fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length = np.arctan(0.5 * ds.camera_angle)\n",
    "print(ds.camera_angle)\n",
    "print(focal_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 800; width = 800\n",
    "x_center = height // 2\n",
    "y_center = width // 2\n",
    "row_coords, col_coords = np.mgrid[0:height, 0:width]\n",
    "row_coords = (row_coords - x_center) / height\n",
    "col_coords = (col_coords - y_center) / width\n",
    "z_axis = np.full((height, width), - focal_length)\n",
    "perspective = np.ones((height, width))\n",
    "\n",
    "cam_coords = np.stack([row_coords, col_coords, z_axis,  perspective], axis=0)\n",
    "print(cam_coords.shape)\n",
    "print(frame['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = frame['image'].numpy().reshape((4,-1))\n",
    "opacity = image[3,:] > 1e-5\n",
    "rgb = image[:3,opacity].T #reshape((-1,3))\n",
    "\n",
    "cam_coords = cam_coords.reshape((4, -1))\n",
    "x, y, z, _ = cam_coords[:,opacity]\n",
    "\n",
    "img_fig = go.Scatter3d(x=x, y=y, z=z,\n",
    "                       mode='markers', marker=dict(\n",
    "                           size=2,\n",
    "                           color=rgb\n",
    "                       ))\n",
    "origin_fig = go.Scatter3d(x=[0], y=[0], z=[0], \n",
    "                       mode='markers', marker=dict(\n",
    "                           size=2,\n",
    "                           color='purple'\n",
    "                      ))\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(img_fig)\n",
    "fig.add_trace(origin_fig)\n",
    "fig.show()\n",
    "\n",
    "fig.write_html(\"./cam_perspective_4.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f59837",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_coords = c2w @ cam_coords\n",
    "x, y, z = world_coords[:3, opacity] / world_coords[3, opacity]\n",
    "\n",
    "img_fig = go.Scatter3d(x=x, y=y, z=z,\n",
    "                       mode='markers', marker=dict(\n",
    "                           size=2,\n",
    "                           color=rgb\n",
    "                       ))\n",
    "cam_x, cam_y, cam_z, _ = cam_points[-1]\n",
    "cam_fig = go.Scatter3d(x=[cam_x], y=[cam_y], z=[cam_z], \n",
    "                       mode='markers', marker=dict(\n",
    "                           size=2,\n",
    "                           color='purple'\n",
    "                      ))\n",
    "\n",
    "\n",
    "origin_fig = go.Scatter3d(x=[0], y=[0], z=[0], \n",
    "                       mode='markers', marker=dict(\n",
    "                           size=2,\n",
    "                           color='red'\n",
    "                      ))\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(img_fig)\n",
    "fig.add_trace(origin_fig)\n",
    "fig.add_trace(cam_fig)\n",
    "fig.show()\n",
    "\n",
    "fig.write_html(\"./world_perspective_4.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
